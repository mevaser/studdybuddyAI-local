import os
import uuid
import pandas as pd
import openai
from pinecone import Pinecone
from dotenv import load_dotenv
import tiktoken

load_dotenv()

# ×”×’×“×¨×•×ª ×§×‘×•×¢×•×ª
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_API_KEY = os.getenv("api_key")
INDEX_NAME = "studybuddy-memory"

openai.api_key = OPENAI_API_KEY
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)

# ×”××¨×ª ×˜×§×¡×˜ ×œ×•×•×§×˜×•×¨
def get_embedding(text):
    response = openai.Embedding.create(
        input=text,
        model="text-embedding-ada-002"
    )
    return response['data'][0]['embedding']

# ×˜×¢×™× ×ª ×§×•×‘×¥ ×”-CSV
csv_path = "selected_fixed.csv"  # ×ª×¢×“×›×Ÿ ×× ×¦×¨×™×š
df = pd.read_csv(csv_path, encoding="utf-8-sig")

# ×¡×¤×™×¨×ª ×¡×”"×›
total_rows = len(df)
uploaded = 0
skipped = 0
errors = 0

print(f"\nğŸš€ ××ª×—×™×œ ×ª×”×œ×™×š ×”×¢×œ××” ×©×œ {total_rows} ×©×•×¨×•×ª ×œ×¤×™×™× ×§×•×Ÿ...\n")

# ××¢×‘×¨ ×¢×œ ×›×œ ×©×•×¨×” ×•×”×¢×œ××” ×œ×¤×™×™× ×§×•×Ÿ
for idx, (_, row) in enumerate(df.iterrows(), start=1):
    try:
        email = str(row["StudentEmail"])
        name = str(row["StudentName"])
        question = str(row["StudentPrompt"])
        answer = str(row["AIAnswer"])
        topic = str(row["topic"])
        subtopic = str(row["subtopic"])
        timestamp = str(row["Timestamp"])

        full_text = f"×©××œ×”: {question}\n×ª×©×•×‘×”: {answer}"
        vector_id = str(uuid.uuid5(uuid.NAMESPACE_DNS, email + timestamp))

        # ×‘×“×™×§×” ×× ×§×™×™× ×›×‘×¨
        existing = index.fetch(ids=[vector_id], namespace="default").vectors
        if vector_id in existing:
            print(f"[{idx}/{total_rows}] âœ” ×¨×©×•××” ×§×™×™××ª (ID: {vector_id}), ××“×œ×’.")
            skipped += 1
            continue

        embedding = get_embedding(full_text)

        index.upsert(
            vectors=[
                {
                    "id": vector_id,
                    "values": embedding,
                    "metadata": {
                        "email": email,
                        "name": name,
                        "question": question,
                        "answer": answer,
                        "topic": topic,
                        "subtopic": subtopic,
                        "timestamp": timestamp
                    }
                }
            ],
            namespace="default"
        )
        print(f"[{idx}/{total_rows}] â¬† ×¨×©×•××” ×”×•×¢×œ×ª×” (ID: {vector_id})")
        uploaded += 1

    except Exception as e:
        print(f"[{idx}/{total_rows}] âš  ×©×’×™××” ×‘×©×•×¨×” {idx}: {e}")
        errors += 1

# ×“×•×— ××¡×›×
print("\nğŸ“Š ×¡×™×›×•× ×ª×”×œ×™×š:")
print(f"×¡×”\"×› ×©×•×¨×•×ª ×‘×§×•×‘×¥: {total_rows}")
print(f"×¨×©×•××•×ª ×—×“×©×•×ª ×©×”×•×¢×œ×•: {uploaded}")
print(f"×¨×©×•××•×ª ×©×“×œ×’×• ×¢×œ×™×”×Ÿ (×›×‘×¨ ×§×™×™××•×ª): {skipped}")
print(f"×©×’×™××•×ª: {errors}")
print("\nâœ… ×¡×™×•× ×ª×”×œ×™×š.")
